import os

import numpy as np
import matplotlib.pyplot as plt


def plot_loss():
    shuffle_train_loss = [0.17773334681987762, 0.09472982585430145, 0.10452558845281601, 0.06102432683110237, 0.07191427797079086, 0.10447192192077637, 0.13669809699058533, 0.05881016328930855, 0.07046014815568924, 0.04816703125834465, 0.07794303447008133, 0.02309596724808216, 0.031033795326948166, 0.040423326194286346, 0.03833186626434326, 0.0650932714343071, 0.032706599682569504, 0.02302483096718788, 0.04023269563913345, 0.04870910197496414, 0.03490409627556801, 0.05679013207554817, 0.024358857423067093, 0.012640191242098808, 0.00874941237270832, 0.015397231094539165, 0.012631746008992195, 0.01777070201933384, 0.01728808507323265, 0.020774763077497482, 0.03915183246135712, 0.010628627613186836, 0.007550491951406002, 0.02082831785082817, 0.007177569903433323, 0.008299239911139011, 0.006004299037158489, 0.03703891113400459, 0.010891018435359001, 0.009589958935976028, 0.012515975162386894, 0.03871161490678787, 0.012162107042968273, 0.007931195199489594, 0.008595935069024563, 0.01457397360354662, 0.012454953975975513, 0.006268019787967205, 0.019581403583288193, 0.014301275834441185, 0.009420252405107021, 0.009281827136874199, 0.01676136441528797, 0.00796064455062151, 0.10393738746643066, 0.008258745074272156, 0.015070946887135506, 0.00709471944719553, 0.016053996980190277, 0.015109886415302753, 0.009835487231612206, 0.012760085053741932, 0.07102267444133759, 0.042702365666627884, 0.013345057144761086, 0.04585840553045273, 0.009868916124105453, 0.006326432339847088, 0.009515607729554176, 0.007385651580989361, 0.007318391464650631, 0.059082649648189545, 0.009464091621339321, 0.032582756131887436, 0.0060191028751432896, 0.006921582855284214, 0.017641859129071236, 0.006241532042622566, 0.008676780387759209, 0.010638214647769928, 0.007749643176794052, 0.006997148040682077, 0.009313637390732765, 0.02172389067709446, 0.00691243028268218, 0.005457769148051739, 0.007893778383731842, 0.006895110011100769, 0.006493575870990753, 0.009308149106800556, 0.01681150123476982, 0.007836667820811272, 0.010216591879725456, 0.00888121034950018, 0.007536617107689381, 0.012319842353463173, 0.012934276834130287, 0.007911070249974728, 0.030508825555443764, 0.008549540303647518, 0.016515713185071945, 0.008360045030713081, 0.013986116275191307, 0.009619436226785183, 0.005988972261548042, 0.00554838078096509, 0.009130943566560745, 0.00755522632971406, 0.007458930369466543, 0.01622490957379341, 0.007530820555984974, 0.007974600419402122, 0.010729908011853695, 0.024555673822760582, 0.020202629268169403, 0.012464819476008415, 0.008488016203045845, 0.005344184581190348, 0.007904944010078907, 0.008889603428542614, 0.017272789031267166, 0.13745447993278503, 0.013474822044372559, 0.005865002982318401, 0.008910482749342918, 0.008409754373133183, 0.008614063262939453, 0.0058280834928154945, 0.029909858480095863, 0.006602602545171976, 0.010900385677814484, 0.01631879061460495, 0.03413831815123558, 0.015968700870871544, 0.0416608564555645, 0.00506585743278265, 0.008600478991866112, 0.015896566212177277, 0.006869163364171982, 0.010302072390913963, 0.023998655378818512, 0.012371129356324673, 0.005129174329340458, 0.007704847492277622, 0.00803663395345211, 0.008051890879869461, 0.007018162868916988, 0.010973081924021244, 0.006655693054199219, 0.03666369616985321]
    shuffle_test_loss = [0.0389816047668457, 0.045109911632537844, 0.04892787256240845, 0.05159940729141235, 0.05346466655731201, 0.055169951820373535, 0.0569808789730072, 0.058891744089126584, 0.06062756567001343, 0.06115401659011841, 0.06351374344825744, 0.06384542989730835, 0.0635337191104889, 0.06571509623527527, 0.06604071984291077, 0.06666230340003967, 0.06611868638992309, 0.06741578221321105, 0.0690186155796051, 0.06909032506942749, 0.06920163464546204, 0.07010156140327453, 0.070062482213974, 0.06971112504005432, 0.07056020717620849, 0.07119528856277466, 0.07107242393493653, 0.07082096581459045, 0.07281081056594849, 0.07344411754608154, 0.0725082908630371, 0.07430437002182007, 0.07213081264495849, 0.07334443483352661, 0.07263138046264649, 0.07370871543884278, 0.07360775880813598, 0.07260267210006714, 0.07393375387191772, 0.07305273952484131, 0.07378238353729248, 0.07383427619934083, 0.07388287925720215, 0.07295929040908813, 0.07458263082504273, 0.07381974897384644, 0.0738814712524414, 0.07351356935501098, 0.07349960489273072, 0.07421983852386474, 0.07495022163391113, 0.0742706337928772, 0.07383501129150391, 0.07480937995910644, 0.07479614515304565, 0.07393321933746339, 0.07515529203414917, 0.07412062788009643, 0.07420987405776977, 0.0745986909866333, 0.07422190799713135, 0.07476362800598145, 0.07502466917037964, 0.07361615724563599, 0.07442137622833252, 0.07386715154647827, 0.07425758628845215, 0.07394030380249024, 0.07416772518157959, 0.07501282730102539, 0.07396351652145386, 0.07400956602096558, 0.07500365629196167, 0.07432006702423095, 0.07401569700241088, 0.07355736846923829, 0.07433415651321411, 0.07454119234085083, 0.07450026216506958, 0.07369048805236816, 0.07431044683456421, 0.07329736900329589, 0.07414526815414428, 0.07355865116119385, 0.07473032054901123, 0.07489123229980468, 0.07373748712539673, 0.07424851026535034, 0.07376138229370117, 0.0742546926498413, 0.07293839406967163, 0.07482896699905396, 0.07324513950347901, 0.07448823194503784, 0.07489902496337891, 0.07428179016113282, 0.07380312557220459, 0.07432791738510132, 0.0747967809677124, 0.0752487319946289, 0.07428812685012817, 0.0744181113243103, 0.07467608375549316, 0.07400592813491821, 0.07482793684005737, 0.07379249925613403, 0.07392362623214721, 0.07483060760498046, 0.07381740093231201, 0.07395371599197388, 0.07359046955108643, 0.0746122730255127, 0.07485266094207764, 0.07416460132598877, 0.0735962080001831, 0.07392489976882935, 0.07472296905517578, 0.0740583685874939, 0.07481253480911255, 0.07567476720809936, 0.07487700920104981, 0.07435287227630616, 0.07390486936569214, 0.07427947473526, 0.0741823805809021, 0.07442990226745605, 0.07412307195663452, 0.07456594696044921, 0.07332916660308837, 0.07401994199752808, 0.07553135757446289, 0.07469047050476074, 0.07396085405349731, 0.07482537336349487, 0.07447867813110351, 0.07410748891830445, 0.07514589099884034, 0.07439105138778687, 0.0742532564163208, 0.07410357294082641, 0.07353038177490234, 0.07396933917999268, 0.07510737161636352, 0.07440315551757813, 0.07410867891311645, 0.07417822713851929, 0.074126411819458, 0.07427456855773926, 0.07452023048400878, 0.07394325885772705]
    main_task_loss = [0.040716500482559204, 0.04848245841026306, 0.053256132974624636, 0.056768452882766725, 0.05929951749801636, 0.061473787994384764, 0.06388776378631592, 0.06619137991905212, 0.06840193108558655, 0.06915964259147644, 0.07200932012557984, 0.07262646879196168, 0.07254461177825927, 0.07535328033447265, 0.07576778461456299, 0.07665448072433471, 0.07601593437194824, 0.07765399110794068, 0.07954954872131348, 0.08000320709228516, 0.08014856115341186, 0.08117455911636352, 0.08130202514648438, 0.08088129240036011, 0.08199679344177246, 0.08291492303848266, 0.08265556125640869, 0.08268609819412231, 0.08486896341323853, 0.08582121601104736, 0.084749418258667, 0.08697889591217041, 0.08467923934936523, 0.08589280242919922, 0.08504148250579834, 0.08642563600540161, 0.08641775177001954, 0.08532472690582275, 0.08702114904403686, 0.08585930995941161, 0.08691709613800049, 0.086878347530365, 0.08709236120224, 0.08614803855895996, 0.0878276494216919, 0.08709341875076294, 0.08725653636932373, 0.08687430181503296, 0.08676353313446045, 0.08775442367553711, 0.08851805917739868, 0.0876628766822815, 0.08733969871520995, 0.08845127840042115, 0.08842462055206299, 0.08744303556442261, 0.08886944416046143, 0.08770565055847168, 0.08784716880798339, 0.08838438547134399, 0.08780984502792358, 0.08837505399703979, 0.0887562899017334, 0.08727842565536499, 0.08824026529312133, 0.08737121507644653, 0.08801685956954956, 0.08766531188964843, 0.08782598022460937, 0.08893209400177002, 0.08764221794128418, 0.08764955419540406, 0.08872418918609619, 0.08798327840805054, 0.0877182576751709, 0.08707130851745605, 0.0880301530456543, 0.08815396936416627, 0.08835494493484497, 0.0873261552810669, 0.0882403183746338, 0.08694561473846435, 0.08773302898406983, 0.08709578048706054, 0.08858463098526001, 0.08875190664291382, 0.08735073263168334, 0.08807994575500488, 0.08740160732269286, 0.0879861724472046, 0.08632739479064941, 0.08888211238861084, 0.0868017085838318, 0.08819119539260864, 0.0887860378074646, 0.08809334819793702, 0.08721048179626464, 0.0880025658416748, 0.08853584053039551, 0.08913387321472167, 0.08796150691986084, 0.08823144598007202, 0.0885380288696289, 0.08770860260009766, 0.08876015119552612, 0.08750575658798218, 0.08761972982406616, 0.08869323125839233, 0.08753641353607178, 0.08767994157791138, 0.08725238409042359, 0.08838507404327392, 0.08859889757156372, 0.08789130344390869, 0.0872164652633667, 0.0876852059173584, 0.0885491117477417, 0.08769849006652831, 0.0886282211303711, 0.08962455045700073, 0.08870252317428588, 0.08804065256118775, 0.08766925643920899, 0.08804349576950073, 0.08791815322875976, 0.0882703034210205, 0.08782612558364868, 0.08843769962310791, 0.08701283874511719, 0.08770793077468872, 0.08942177482604981, 0.08856155591964722, 0.08782099489212036, 0.08879617261886597, 0.08826763914108277, 0.08787823383331299, 0.08915127313613892, 0.08815569957733155, 0.08805948862075806, 0.08791795957565307, 0.08715976209640502, 0.08781642137527466, 0.08882455955505371, 0.08817769071578979, 0.08780049970626831, 0.08788946495056152, 0.08786931980133057, 0.0880600133895874, 0.08836523021697998, 0.0877132124710083]
    backdoor_attack_loss = [0.17178385513305663, 0.2246404644012451, 0.2334358289337158, 0.26693917400360107, 0.2914360648345947, 0.28314548751831053, 0.30807366065979, 0.28982927574157713, 0.2788403050994873, 0.2732867459487915, 0.27560515830993654, 0.2897349292373657, 0.26831269214630127, 0.2608472785186768, 0.25450387897491455, 0.2541864334487915, 0.26118092292785644, 0.25225906520843505, 0.2226798310470581, 0.24584324478149414, 0.24325667278289795, 0.23427050331115723, 0.23047806091308592, 0.22380096210479736, 0.21887909481048584, 0.23662305961608887, 0.21852132865905763, 0.22929404224395752, 0.21231415874481202, 0.22634640281677246, 0.22606861778259277, 0.2064606226348877, 0.20796475860595703, 0.19916193347930908, 0.19364674739837648, 0.18645159114837648, 0.1809266550064087, 0.19151148616790772, 0.1691974803543091, 0.1749088556289673, 0.18324880855560302, 0.1691218231201172, 0.16748348197937013, 0.17025353210449218, 0.1622158736038208, 0.16567371757507324, 0.1682270707321167, 0.15879386501312256, 0.16587783515930177, 0.15688021839141847, 0.15969355705261232, 0.15922188262939452, 0.15908263500213624, 0.15760105804443358, 0.15380582649230956, 0.15250206052780152, 0.151225319480896, 0.1521836206817627, 0.15299648551940917, 0.1571290830230713, 0.15819382068634033, 0.14954384874343873, 0.15522952436447143, 0.14873842536926268, 0.1447968214416504, 0.15693337802886964, 0.15660500827789306, 0.15261398012161254, 0.1474807597351074, 0.15635864944458008, 0.15336347434997558, 0.1566245665359497, 0.1479860540008545, 0.1459671152496338, 0.1477130449295044, 0.15318669277191163, 0.1505115881729126, 0.15911907665252686, 0.1538238529777527, 0.15476421215057373, 0.1572147508239746, 0.1514571515083313, 0.15202286151885985, 0.15194202352523803, 0.14998894693374634, 0.14709345008850097, 0.15637551664352417, 0.1516286930847168, 0.1493544658279419, 0.154597000541687, 0.15712237533569337, 0.15129556171417236, 0.14876511167526246, 0.1528415203475952, 0.1515106748199463, 0.14602131971359253, 0.1566497383880615, 0.1516861904335022, 0.1520314807510376, 0.15837986831665038, 0.15427476837158202, 0.14562789415359498, 0.15621492084503175, 0.15049041749954223, 0.1529108964920044, 0.14955592723846436, 0.15303155445098876, 0.15287546314239503, 0.15373268466949463, 0.1456573713874817, 0.14955752895355223, 0.1532167753982544, 0.15789493259429932, 0.15099984134674072, 0.1522684015083313, 0.15667917999267578, 0.1545039326095581, 0.15675806491851807, 0.15288840244293214, 0.14531237453460694, 0.1485852982711792, 0.15276090744018556, 0.1547236775970459, 0.15311306224823, 0.14207581497192384, 0.1524111213684082, 0.1525290129852295, 0.15326582794189453, 0.14542133947372438, 0.15082131057739256, 0.15837370517730712, 0.1575807596206665, 0.15133725881576537, 0.1505609293746948, 0.14873942966461182, 0.1548889298629761, 0.15498506086349487, 0.14982205699920653, 0.1546539299583435, 0.15666962352752686, 0.152794959564209, 0.1529879666519165, 0.14714427059173585, 0.15023833187103272, 0.15719500728607178, 0.15183572540283202, 0.14778256223678587, 0.14713865968704223, 0.14792591274261474, 0.15597158874511718]
    main_task_acc = [0.81, 0.304, 0.122, 0.092, 0.072, 0.046, 0.038, 0.034, 0.026, 0.028, 0.012, 0.01, 0.016, 0.016, 0.014, 0.01, 0.016, 0.01, 0.008, 0.008, 0.008, 0.008, 0.008, 0.006, 0.004, 0.006, 0.002, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002, 0.004, 0.0, 0.0, 0.0, 0.002, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.002, 0.002, 0.0, 0.0, 0.002, 0.002, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002]
    backdoor_attack_acc = [65.976, 98.67, 98.428, 98.818, 97.58, 99.608, 99.268, 98.594, 98.958, 98.632, 96.43, 98.184, 95.942, 96.032, 95.694, 94.762, 96.182, 94.01, 88.632, 95.552, 93.512, 91.256, 92.432, 91.852, 89.498, 92.888, 90.934, 92.352, 83.99, 90.806, 86.988, 82.742, 87.66, 82.828, 79.84, 62.66, 65.088, 78.022, 48.834, 60.46, 74.85, 59.106, 59.486, 64.86, 33.942, 45.218, 33.084, 46.522, 46.614, 25.596, 22.086, 30.036, 43.614, 32.904, 39.44, 16.986, 47.512, 34.27, 18.226, 33.008, 15.142, 23.57, 30.284, 33.856, 25.718, 15.198, 36.862, 28.72, 31.614, 38.364, 24.992, 38.224, 11.466, 17.31, 28.012, 22.296, 13.962, 9.22, 25.498, 10.39, 38.506, 32.85, 14.504, 38.672, 37.556, 13.126, 10.396, 29.358, 19.706, 13.328, 35.164, 20.894, 19.658, 13.542, 21.77, 25.426, 19.03, 25.688, 8.57, 30.6, 18.848, 18.992, 6.16, 21.316, 14.044, 25.244, 10.81, 21.138, 31.778, 23.406, 13.928, 16.848, 6.072, 25.38, 7.936, 16.908, 6.486, 5.006, 19.912, 16.11, 3.154, 19.692, 11.342, 15.596, 13.506, 17.608, 14.094, 10.012, 20.914, 23.47, 7.716, 19.1, 20.002, 11.02, 12.99, 25.894, 22.594, 18.884, 17.3, 41.71, 20.058, 9.592, 28.2, 16.02, 18.034, 12.952, 20.322, 11.94, 13.814, 22.298]

    epochs = list(range(1, len(shuffle_test_loss)+1))

    # 1. 画布背景设置
    fig, ax = plt.subplots(1, 1)
    ax.grid(which="major", ls="--", lw=1.0, c="gray")

    # 2. 坐标轴设置
    # ax.set_xticks(ratios)  # 设置刻度
    # ax.set_xticklabels([f"{ratio}" for ratio in ratios])  # 设置刻度标签
    # plt.xticks(fontsize=14)
    # plt.yticks(fontsize=14)
    # plt.ylim(0, 1.05)

    # Plotting the extended loss curves
    # marker 类型: o: 圆形, *: 五角星, v: 三角形, s: 正方形
    # google 配色: #f4433c 红色, #ffbc32 黄色, #0aa858 绿色, #2d85f0 蓝色
    plt.figure(figsize=(12, 8))
    plt.plot(epochs, shuffle_train_loss, marker='o', linestyle='-', color='b', markevery=10, label='Shuffle Train Loss')
    plt.plot(epochs, main_task_loss, marker='s', linestyle='--', color='g', markevery=10, label='Main Task Losses')
    plt.plot(epochs, backdoor_attack_loss, marker='^', linestyle='-.', color='r', markevery=10, label='Backdoor Attack Losses')

    # Adding titles and labels
    plt.title('Loss Curves for Different Tasks')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.savefig("loss.png")
    plt.close()


def plot_acc():
    main_task_acc = [0.805, 0.81, 0.304, 0.122, 0.092, 0.072, 0.046, 0.038, 0.034, 0.026, 0.028, 0.012, 0.01, 0.016, 0.016, 0.014, 0.01, 0.016, 0.01, 0.008, 0.008, 0.008, 0.008, 0.008, 0.006, 0.004, 0.006, 0.002, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002, 0.004, 0.0, 0.0, 0.0, 0.002, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.002, 0.002, 0.0, 0.0, 0.002, 0.002, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002]
    backdoor_attack_acc = [100.00, 65.976, 98.67, 98.428, 98.818, 97.58, 99.608, 99.268, 98.594, 98.958, 98.632, 96.43, 98.184, 95.942, 96.032, 95.694, 94.762, 96.182, 94.01, 88.632, 95.552, 93.512, 91.256, 92.432, 91.852, 89.498, 92.888, 90.934, 92.352, 83.99, 90.806, 86.988, 82.742, 87.66, 82.828, 79.84, 62.66, 65.088, 78.022, 48.834, 60.46, 74.85, 59.106, 59.486, 64.86, 33.942, 45.218, 33.084, 46.522, 46.614, 25.596, 22.086, 30.036, 43.614, 32.904, 39.44, 16.986, 47.512, 34.27, 18.226, 33.008, 15.142, 23.57, 30.284, 33.856, 25.718, 15.198, 36.862, 28.72, 31.614, 38.364, 24.992, 38.224, 11.466, 17.31, 28.012, 22.296, 13.962, 9.22, 25.498, 10.39, 38.506, 32.85, 14.504, 38.672, 37.556, 13.126, 10.396, 29.358, 19.706, 13.328, 35.164, 20.894, 19.658, 13.542, 21.77, 25.426, 19.03, 25.688, 8.57, 30.6, 18.848, 18.992, 6.16, 21.316, 14.044, 25.244, 10.81, 21.138, 31.778, 23.406, 13.928, 16.848, 6.072, 25.38, 7.936, 16.908, 6.486, 5.006, 19.912, 16.11, 3.154, 19.692, 11.342, 15.596, 13.506, 17.608, 14.094, 10.012, 20.914, 23.47, 7.716, 19.1, 20.002, 11.02, 12.99, 25.894, 22.594, 18.884, 17.3, 41.71, 20.058, 9.592, 28.2, 16.02, 18.034, 12.952, 20.322, 11.94, 13.814, 22.298]
    backdoor_attack_acc = [acc/100 for acc in backdoor_attack_acc]
    epochs = list(range(1, len(main_task_acc)+1))
    print(len(main_task_acc), len(backdoor_attack_acc), len(epochs))

    # epochs = epochs[: 20]
    # main_task_acc = main_task_acc[: 20]
    # backdoor_attack_acc = backdoor_attack_acc[: 20]

    fig, ax = plt.subplots(1, 1)
    ax.grid(which="major", ls="--", lw=1.0, c="gray")

    x_scale = epochs[::5]  # 每隔5个数的值
    ax.set_xticks(x_scale)  # 设置刻度
    ax.set_xticklabels([f"{scale}" for scale in x_scale])  # 设置刻度标签

    plt.figure(figsize=(12, 8))
    plt.plot(epochs, main_task_acc, marker='o', linestyle='-', linewidth=2.6, color='b', markevery=4, label='Main Task Acc')
    plt.plot(epochs, backdoor_attack_acc, marker='s', linestyle='--', linewidth=2.6, color='g', markevery=4, label='Backdoor Task Acc')

    plt.title('Acc Curves for Different Tasks')
    plt.xlabel('Epochs')
    plt.ylabel('Acc')
    plt.legend()
    plt.grid(True)

    plt.savefig("acc.png")
    plt.close()


def plot_acc_new(main_task_acc, backdoor_attack_acc, save_fig):
    epochs = list(range(len(main_task_acc)))
    linewidth = 1.8
    markersize = 6
    labelsize = 18
    legendsize = 14
    pic_type = "pdf"  # pdf, png
    ticksize = 12
    bwith = 2
    lwith = 1.5

    fig, ax = plt.subplots(1, 1)
    # ax.grid(which="major", ls="--", lw=1.0, c="gray")
    ax.spines['bottom'].set_linewidth(bwith)
    ax.spines['left'].set_linewidth(bwith)
    ax.spines['top'].set_linewidth(bwith)
    ax.spines['right'].set_linewidth(bwith)
    ax.grid(which="major", ls="--", lw=lwith, c="gray")

    # 2. 坐标轴设置
    x_ticks = list(range(0, len(epochs) + 1, 10))
    ax.set_xticks(x_ticks)
    ax.set_xticklabels([f"{x}" for x in x_ticks], fontsize=ticksize)  # 设置刻度标签

    ax.set_ylim(-0.05, 1.05)
    y_ticks = np.arange(0, 1.05, 0.2)
    ax.set_yticks(y_ticks)
    ax.set_yticklabels([f"{y :.1f}" for y in y_ticks], fontsize=ticksize)  # 设置刻度标签

    # marker 类型: o: 圆形, *: 五角星, v: 三角形, s: 正方形
    # google 配色: #f4433c 红色, #ffbc32 黄色, #0aa858 绿色, #2d85f0 蓝色
    ax.plot(
        epochs,
        main_task_acc,
        label="Main Task Acc",
        ls="--",
        linewidth=linewidth,
        c="#0aa858",
        marker="v",
        markersize=markersize,
        markevery=10,
    )
    ax.plot(
        epochs,
        backdoor_attack_acc,
        label="Backdoor Task ASR Acc",
        ls="-",
        linewidth=linewidth,
        c="#f4433c",
        marker="o",
        markersize=markersize,
        markevery=10,
    )
    ax.set_xlabel("Epochs", fontsize=labelsize)
    ax.set_ylabel("Acc", fontsize=labelsize)
    ax.legend(fontsize=legendsize, loc="upper right") # lower right

    plt.figsize = (16, 9)
    plt.tight_layout()
    plt.savefig(save_fig)
    plt.close()

save_dir = "../../results/pretest/shuffle_train"
abs_save_dir = os.path.abspath(save_dir)
if not os.path.exists(abs_save_dir):
    os.makedirs(abs_save_dir)

# # Running experiment with args: load_model=2, train_bottom_model_b=False, shuffle_label_way=class_to_class, lr=0.002, shuffle_epochs=150, batch_size=128
# main_task_acc = [0.81, 0.304, 0.122, 0.092, 0.072, 0.046, 0.038, 0.034, 0.026, 0.028, 0.012, 0.01, 0.016, 0.016, 0.014, 0.01, 0.016, 0.01, 0.008, 0.008, 0.008, 0.008, 0.008, 0.006, 0.004, 0.006, 0.002, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002, 0.004, 0.0, 0.0, 0.0, 0.002, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.002, 0.002, 0.0, 0.0, 0.002, 0.002, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002]
# backdoor_attack_acc = [65.976, 98.67, 98.428, 98.818, 97.58, 99.608, 99.268, 98.594, 98.958, 98.632, 96.43, 98.184, 95.942, 96.032, 95.694, 94.762, 96.182, 94.01, 88.632, 95.552, 93.512, 91.256, 92.432, 91.852, 89.498, 92.888, 90.934, 92.352, 83.99, 90.806, 86.988, 82.742, 87.66, 82.828, 79.84, 62.66, 65.088, 78.022, 48.834, 60.46, 74.85, 59.106, 59.486, 64.86, 33.942, 45.218, 33.084, 46.522, 46.614, 25.596, 22.086, 30.036, 43.614, 32.904, 39.44, 16.986, 47.512, 34.27, 18.226, 33.008, 15.142, 23.57, 30.284, 33.856, 25.718, 15.198, 36.862, 28.72, 31.614, 38.364, 24.992, 38.224, 11.466, 17.31, 28.012, 22.296, 13.962, 9.22, 25.498, 10.39, 38.506, 32.85, 14.504, 38.672, 37.556, 13.126, 10.396, 29.358, 19.706, 13.328, 35.164, 20.894, 19.658, 13.542, 21.77, 25.426, 19.03, 25.688, 8.57, 30.6, 18.848, 18.992, 6.16, 21.316, 14.044, 25.244, 10.81, 21.138, 31.778, 23.406, 13.928, 16.848, 6.072, 25.38, 7.936, 16.908, 6.486, 5.006, 19.912, 16.11, 3.154, 19.692, 11.342, 15.596, 13.506, 17.608, 14.094, 10.012, 20.914, 23.47, 7.716, 19.1, 20.002, 11.02, 12.99, 25.894, 22.594, 18.884, 17.3, 41.71, 20.058, 9.592, 28.2, 16.02, 18.034, 12.952, 20.322, 11.94, 13.814, 22.298]
# main_task_acc.insert(0, 80.5)
# backdoor_attack_acc.insert(0, 100.0)
# main_task_acc = [acc/100 for acc in main_task_acc]
# backdoor_attack_acc = [acc/100 for acc in backdoor_attack_acc]
# save_fig = os.path.join(save_dir, "acc1.pdf")
# plot_acc_new(main_task_acc, backdoor_attack_acc, save_fig)

# # Running experiment with args: load_model=2, train_bottom_model_b=False, shuffle_label_way=class_to_class, lr=0.0001, shuffle_epochs=100, batch_size=128
# main_task_acc = [13.966, 4.192, 2.152, 1.554, 0.598, 0.494, 0.392, 0.522, 0.386, 0.29, 0.464, 0.236, 0.282, 0.306, 0.16, 0.266, 0.148, 0.214, 0.146, 0.194, 0.12, 0.178, 0.19, 0.106, 0.096, 0.098, 0.102, 0.128, 0.102, 0.094, 0.136, 0.118, 0.144, 0.092, 0.118, 0.06, 0.082, 0.074, 0.088, 0.054, 0.07, 0.07, 0.048, 0.068, 0.062, 0.052, 0.048, 0.052, 0.054, 0.052, 0.048, 0.046, 0.054, 0.04, 0.052, 0.042, 0.068, 0.04, 0.04, 0.038, 0.056, 0.058, 0.048, 0.048, 0.06, 0.07, 0.058, 0.058, 0.04, 0.054, 0.044, 0.048, 0.054, 0.038, 0.044, 0.04, 0.046, 0.032, 0.04, 0.04, 0.048, 0.05, 0.044, 0.038, 0.044, 0.078, 0.05, 0.036, 0.042, 0.04, 0.042, 0.05, 0.04, 0.058, 0.042, 0.058, 0.046, 0.042, 0.048, 0.054]
# backdoor_attack_acc = [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.97, 99.974, 99.992, 99.86, 99.488, 99.096, 99.508, 96.94, 94.306, 90.74, 91.43, 69.788, 51.682, 48.714, 38.426, 57.932, 58.876, 48.578, 27.426, 26.31, 39.172, 38.146, 44.238, 43.324, 10.064, 29.46, 41.674, 33.948, 23.774, 28.272, 20.132, 15.03, 14.064, 14.028, 18.532, 13.154, 13.252, 14.184, 7.69, 14.434, 5.066, 11.73, 10.422, 7.358, 10.664, 6.298, 8.828, 9.534, 13.72, 6.858, 9.706, 3.378, 4.16, 11.782, 8.742, 13.48, 7.324, 11.57, 3.598, 7.168, 8.652, 6.688, 5.472, 10.842, 12.084, 7.89, 12.966, 2.352, 5.5, 5.294, 2.918, 17.138, 8.34, 5.608, 4.654, 4.548, 5.804, 4.544, 4.338, 4.216, 4.752, 1.018, 3.72, 8.814, 4.48, 4.932, 2.612, 4.448, 3.388, 8.188]
# main_task_acc.insert(0, 80.5)
# backdoor_attack_acc.insert(0, 100.0)
# main_task_acc = [acc/100 for acc in main_task_acc]
# backdoor_attack_acc = [acc/100 for acc in backdoor_attack_acc]
# save_fig = os.path.join(abs_save_dir, "acc2.pdf")
# plot_acc_new(main_task_acc, backdoor_attack_acc, save_fig)

# Running experiment with args: load_model=2, train_bottom_model_b=False, shuffle_label_way=class_to_class, lr=0.001, shuffle_epochs=150, batch_size=128
main_task_acc = [9.632, 2.954, 0.362, 0.148, 0.11, 0.074, 0.07, 0.054, 0.04, 0.036, 0.03, 0.018, 0.024, 0.018, 0.016, 0.012, 0.016, 0.014, 0.012, 0.01, 0.006, 0.006, 0.012, 0.006, 0.006, 0.014, 0.01, 0.008, 0.01, 0.01, 0.008, 0.008, 0.008, 0.01, 0.012, 0.01, 0.008, 0.008, 0.006, 0.004, 0.008, 0.006, 0.006, 0.004, 0.004, 0.004, 0.004, 0.006, 0.004, 0.004, 0.008, 0.008, 0.006, 0.006, 0.006, 0.004, 0.004, 0.006, 0.006, 0.004, 0.008, 0.004, 0.006, 0.004, 0.008, 0.006, 0.006, 0.006, 0.004, 0.006, 0.008, 0.004, 0.004, 0.004, 0.008, 0.006, 0.004, 0.004, 0.006, 0.006, 0.006, 0.006, 0.006, 0.004, 0.004, 0.004, 0.004, 0.008, 0.006, 0.006, 0.004, 0.004, 0.004, 0.004, 0.004, 0.006, 0.004, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.006, 0.004, 0.004, 0.008, 0.006, 0.006, 0.01, 0.006, 0.004, 0.004, 0.006, 0.006, 0.004, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.008, 0.004, 0.006, 0.004, 0.01, 0.006, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.008, 0.006, 0.004, 0.008, 0.002, 0.008, 0.008, 0.008, 0.004, 0.004, 0.008, 0.006, 0.01]
backdoor_attack_acc = [85.706, 97.32, 77.29, 14.912, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
main_task_acc.insert(0, 80.5)
backdoor_attack_acc.insert(0, 100.0)
main_task_acc = [acc/100 for acc in main_task_acc]
backdoor_attack_acc = [acc/100 for acc in backdoor_attack_acc]
save_fig = os.path.join(abs_save_dir, "acc3.pdf")
plot_acc_new(main_task_acc, backdoor_attack_acc, save_fig)

main_task_acc = [10.846, 11.548, 11.762, 11.806, 11.15, 9.896, 8.516, 7.61, 6.158, 5.208, 4.016, 3.702, 3.044, 2.726, 2.542, 2.416, 2.38, 2.048, 2.004, 1.966, 1.936, 1.862, 1.872, 1.904, 1.764, 1.734, 1.75, 1.72, 1.672, 1.656, 1.712, 1.68, 1.62, 1.646, 1.618, 1.622, 1.616, 1.656, 1.584, 1.524, 1.556, 1.638, 1.53, 1.546, 1.582, 1.54, 1.532, 1.538, 1.578, 1.514]
backdoor_attack_acc = [99.754, 98.22, 98.678, 99.922, 99.994, 99.978, 100.0, 99.998, 99.996, 100.0, 100.0, 99.892, 99.128, 97.264, 91.126, 55.432, 6.78, 2.38, 0.424, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
main_task_acc.insert(0, 80.5)
backdoor_attack_acc.insert(0, 100.0)
main_task_acc = [acc/100 for acc in main_task_acc]
backdoor_attack_acc = [acc/100 for acc in backdoor_attack_acc]
save_fig = os.path.join(abs_save_dir, "acc4.pdf")
plot_acc_new(main_task_acc, backdoor_attack_acc, save_fig)